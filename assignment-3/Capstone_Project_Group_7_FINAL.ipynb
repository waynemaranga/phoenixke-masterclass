{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waynemaranga/phoenixke-masterclass/blob/main/Capstone_Project_Group_7_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeHuMTyIEhgB"
      },
      "source": [
        "# `Capstone Project Group 7`\n",
        "\n",
        "Dennis, Joan, Lisa and Wayne.\n",
        "\n",
        "`The Best`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL3lS6EmEqw2"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjckNcqFPBvk"
      },
      "source": [
        "imports the necessary Python libraries for the project:\n",
        "`requests`: To send HTTP requests and get the HTML content of web pages.`BeautifulSoup` (from `bs4`): To parse the HTML content and make it easy to navigate and extract data. `time`: To add delays between requests to avoid overloading the server. `csv`: To handle writing the scraped data into CSV files. `os`: To interact with the operating system, specifically for creating directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaFy4KNlzSp9"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import csv # for csv file operations\n",
        "import os # to access operating system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_N2uJf4Ew1Q"
      },
      "source": [
        "## Request Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-LcAgc9PRyX"
      },
      "source": [
        "This section defines the global constants that will be used throughout the scraping process. `BASE_URL`: Sets the target website to http://books.toscrape.com/. `HEADERS`: Defines a user-agent to make the script's requests look like they're coming from a browser. `SLEEP_TIME`: Sets a 1-second delay between requests to be respectful to the website's server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0os7BT3zUZo"
      },
      "outputs": [],
      "source": [
        "BASE_URL = \"http://books.toscrape.com/\" # one base to request multiple URLs/pages without repeating too many times\n",
        "HEADERS = {\"User-Agent\": \"ScraperBotbyLisaDennisandWayne\"} # a request header; carries info about the request; for scraping rules\n",
        "SLEEP_TIME = 1  # seconds between requests; some delays for respecting sites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrs3813NFK27"
      },
      "source": [
        "## Core Scraping Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOb-EzpdP3ao"
      },
      "source": [
        "This part contains the main functions responsible for fetching and parsing the data. `get_soup(url)`: This function takes a URL, fetches the page content, and returns it as a `BeautifulSoup` object. It includes error handling to catch and report issues if a URL is invalid or fails to load. `convert_star_rating(star_str)`: A helper function that converts the book's star rating from text (e.g., \"Three\") to a numerical value (e.g., 3). `extract_product_info(product)`: This function is designed to parse the HTML of a single book listing. It extracts the Title, Price, Availability, Star Rating, and URL for one book. It also includes basic error handling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbrN12xMQNJs"
      },
      "source": [
        "### `get_soup(url)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYjhVrZdzZSR"
      },
      "outputs": [],
      "source": [
        "# -- A soup is a site's html as a string\n",
        "def get_soup(url):\n",
        "    try:\n",
        "        response = requests.get(url, headers=HEADERS) # gets the HTML as raw html using the headers\n",
        "        response.raise_for_status() # raises error if any with http error code\n",
        "        return BeautifulSoup(response.text, \"html.parser\") # returns the soup and the parser to use\n",
        "\n",
        "        # This except block handles any error with the requests function for example invalid urls\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"[ERROR] Failed to fetch {url} - {e}\")\n",
        "        return None\n",
        "    except Exception as ex:\n",
        "      print(f\"[ERROR] Encountered ambiguous error: - {ex}\")\n",
        "      return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nA_9T2FadhO"
      },
      "source": [
        "### Demonstrating error handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJNrIllC1bNe",
        "outputId": "87a15675-2504-4af6-e48c-4736ca910dfd"
      },
      "outputs": [],
      "source": [
        "print(str(get_soup(\"https://www.facebook.com\"))[:99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afREB6zKaJuH",
        "outputId": "b5157e85-80bc-4790-814a-0161d4884549"
      },
      "outputs": [],
      "source": [
        "print(get_soup(\"www.facebook.com\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F14205WmaUFE",
        "outputId": "299582b8-6f58-4fad-8b48-9907c54e97d8"
      },
      "outputs": [],
      "source": [
        "print(get_soup(\"https://www.facebooksz.com\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzWsbFgAQSpr"
      },
      "source": [
        "### `extract_product_info(product)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jHg4dhvzqto"
      },
      "outputs": [],
      "source": [
        "# -- This function is tailored the books to scrape site\n",
        "def extract_product_info(product):\n",
        "    try:\n",
        "      # This information is got from inspecting the page using developer tools\n",
        "      # Each item (likely) belongs in a tag, a nested tag or something close to it\n",
        "      # 1. Inspect page 2. Inspect page using\n",
        "        title = product.h3.a['title'].strip()\n",
        "        relative_url = product.h3.a['href']\n",
        "        product_url = BASE_URL + 'catalogue/' + relative_url.replace('../../../', '')\n",
        "        price = product.select_one('.price_color').text.strip().replace('£', '') # .select_one(identifier) finds any html element using this identifier/class/attribute and returns a list or one item\n",
        "        availability = product.select_one('.availability').text.strip()\n",
        "        star_class = product.select_one('.star-rating')['class']\n",
        "        star_rating = convert_star_rating(star_class[1]) # converts html star elements into a rating\n",
        "\n",
        "        # Go to individual product page for verification or more details\n",
        "        return {\n",
        "            \"Title\": title,\n",
        "            \"Price\": price,\n",
        "            \"Availability\": availability,\n",
        "            \"Star Rating\": star_rating,\n",
        "            \"URL\": product_url\n",
        "        }\n",
        "        # handles any error\n",
        "    except Exception as e: # uses Python's base Exception which handles all exceptions\n",
        "        print(f\"[ERROR] Failed to parse product info - {e}\")\n",
        "        return None\n",
        "\n",
        "    except KeyboardInterrupt as k:\n",
        "      return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZxiFAyeQatF"
      },
      "source": [
        "### `convert_star_rating(star_str)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNBAVsh_zuN8"
      },
      "outputs": [],
      "source": [
        "# Not essential\n",
        "def convert_star_rating(star_str):\n",
        "    stars = {\n",
        "        \"One\": 1, \"Two\": 2, \"Three\": 3,\n",
        "        \"Four\": 4, \"Five\": 5\n",
        "    }\n",
        "    return stars.get(star_str, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHu-ykKiQ0Tw"
      },
      "source": [
        "## Category and Pagination Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng3RrtvKQ39h"
      },
      "source": [
        "These functions manage the multi-level scraping required for the site structure. `get_categories()`: This function scrapes the website's homepage to get a list of all available book categories and their unique URLs. `get_category_pages(category_url)`: This function handles pagination. For any given category page, it checks how many pages of books exist and returns a complete list of URLs for all pages in that category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcg8m5CCQe9j"
      },
      "source": [
        "### `get_categories()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYMXzD0atheO"
      },
      "outputs": [],
      "source": [
        "# Getting categories in the first place from homepage\n",
        "def get_categories():\n",
        "    soup = get_soup(BASE_URL) # get the soup of the homepage\n",
        "    if not soup:\n",
        "        return {}\n",
        "\n",
        "    category_links = soup.select('.side_categories ul li ul li a') # from the soup get the list and urls of categories\n",
        "    categories = {} # dictionary for category name and url\n",
        "    for a in category_links:\n",
        "        name = a.text.strip()\n",
        "        rel_url = a['href'] # e.g '/catalogue/category/books_1/index.html'\n",
        "        full_url = BASE_URL + rel_url # add base url to relative url : https://books.toscrape.com/catalogue/category/books_1/index.html\n",
        "        categories[name] = full_url\n",
        "    return categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgzLjx5M7s_b",
        "outputId": "008df21b-e6f6-42d8-e862-ff68bff268c1"
      },
      "outputs": [],
      "source": [
        "print(get_categories())\n",
        "print(list(get_categories().keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0iDyseiQkXU"
      },
      "source": [
        "### `get_category_pages(category_url)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPgd_Bhozw04"
      },
      "outputs": [],
      "source": [
        "# Since the page has many categories; for each category get it's soup\n",
        "# Pagination function; made possible by inspection\n",
        "def get_category_pages(category_url):\n",
        "    pages = [category_url]\n",
        "    soup = get_soup(category_url)\n",
        "    if not soup:\n",
        "        return []\n",
        "\n",
        "    pager = soup.select_one('.current') # select current page\n",
        "    if pager:\n",
        "        total_pages = int(pager.text.strip().split()[-1]) # get no. of pages\n",
        "        for page_num in range(2, total_pages + 1):\n",
        "            paginated_url = category_url.replace('index.html', f'page-{page_num}.html') # replace current page with page no.s\n",
        "            pages.append(paginated_url)\n",
        "    return pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l049V1777-c9",
        "outputId": "9620067a-73bf-4fd6-a49a-c69786c8218b"
      },
      "outputs": [],
      "source": [
        "print(get_category_pages(\"http://books.toscrape.com/catalogue/category/books/default_15/index.html\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxhWoIwR8TjF",
        "outputId": "75aee8af-3342-4c39-a0f1-dbca52cdeffe"
      },
      "outputs": [],
      "source": [
        "print(get_category_pages(\"http://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok4g9WXORTd6"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CjaBL8uRG-y"
      },
      "source": [
        "This section brings all the functions together to run the scraper and save the results. `scrape_category(...)`: An orchestrator function that takes a category name and URL, gets all of its pages, scrapes the product info from each page, and then calls the save_to_csv function. `save_to_csv(...)`: This function takes the scraped data for a category and writes it to a uniquely named CSV file (e.g., mystery.csv) inside an output directory. `main()`: The main function that starts the process. In this notebook, it's configured to scrape the first three categories as a sample run. The final cells in this section execute the scraper by calling `main()` and then list the files in the output directory to confirm that the CSV files were created successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ujA6c3D121I",
        "outputId": "301105c1-644a-4ce8-8ccd-4510f012da7b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPknobiwXObK"
      },
      "source": [
        "### Output `folder`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6kfSVe52KLd"
      },
      "outputs": [],
      "source": [
        "folder = '/content/drive/MyDrive/PhoenixKEMasterclass/Capstone/output'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af3C6jq2QpuC"
      },
      "source": [
        "### `save_to_csv(category, data)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2afkGchk9cEV"
      },
      "outputs": [],
      "source": [
        "def save_to_csv(category, data):\n",
        "    filename = f\"{folder}/{category.replace(' ', '_').lower()}.csv\"\n",
        "    with open(filename, \"w\", newline='', encoding='utf-8') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\"Title\", \"Price\", \"Availability\", \"Star Rating\", \"URL\"])\n",
        "        writer.writeheader()\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "    print(f\"[SUCCESS] Saved {len(data)} items to {filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuY2qrd2RkYv"
      },
      "source": [
        "### `scrape_category(category_name, category_url)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uXdZdkh0SwP"
      },
      "outputs": [],
      "source": [
        "# Scrape category...\n",
        "def scrape_category(category_name, category_url):\n",
        "    print(f\"\\n[INFO] Scraping category: {category_name}\")\n",
        "    all_data = []\n",
        "    pages = get_category_pages(category_url) # all pages in category to be scraped\n",
        "\n",
        "    for page_url in pages:\n",
        "        print(f\"[INFO] Scraping page: {page_url}\")\n",
        "        soup = get_soup(page_url) # get the soup\n",
        "        if not soup:\n",
        "            continue\n",
        "\n",
        "        products = soup.select('article.product_pod') # find a product card\n",
        "        for product in products:\n",
        "            info = extract_product_info(product) # from product extract info e.g title and price\n",
        "            if info:\n",
        "                all_data.append(info)\n",
        "        time.sleep(SLEEP_TIME)\n",
        "\n",
        "    save_to_csv(category_name, all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ4YuiD8GuuO",
        "outputId": "2eb95c24-58f9-4dd1-ab13-691a7d6818cb"
      },
      "outputs": [],
      "source": [
        "categories_list = list(get_categories().keys())\n",
        "try:\n",
        "    categories_list.remove('Default')\n",
        "except ValueError:\n",
        "    print(\"'Default' not found in categories_list. Skipping removal.\")\n",
        "\n",
        "try:\n",
        "    categories_list.remove('Add a Comment')\n",
        "except ValueError:\n",
        "    print(\"'Add a Comment' not found in categories_list. Skipping removal.\")\n",
        "\n",
        "\n",
        "print(categories_list)\n",
        "# categories_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37BwIONuRveY"
      },
      "source": [
        "### `main()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "muJknA0N0COQ"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    categories = get_categories() # get all categories\n",
        "    if not categories:\n",
        "        print(\"[ERROR] No categories found.\")\n",
        "        return\n",
        "\n",
        "    selected_categories = list(categories.items())[:10]  #\n",
        "    # selected_categories = list(categories.items())  # Take any 5 categories; these are dictionaries\n",
        "    for category_name, category_url in selected_categories: # name is key, url is value\n",
        "        scrape_category(category_name, category_url) # scrape and write to csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em0Y_48X1sKY",
        "outputId": "dc52b767-2994-4888-96c0-85b70403d200"
      },
      "outputs": [],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSFwtu6hSCHk"
      },
      "source": [
        "## Setup analysis and visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l5QdTTCSKTJ"
      },
      "source": [
        "This is where the notebook transitions from scraping to analysis. The script reads all the newly created CSV files from the output directory and loads them into `pandas` `DataFrame` objects. It imports the visualization libraries `matplotlib` and `seaborn`. The DataFrames are then cleaned and prepared for analysis by dropping unnecessary columns and fixing data types. Finally, all the individual DataFrames are combined into a single combined_df to make plotting easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT_0Q0PoXkdD"
      },
      "source": [
        "### Output `files`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cdBV5BWx2Qqw",
        "outputId": "8d337f08-b779-4ade-dd0c-24de8060b175"
      },
      "outputs": [],
      "source": [
        "files = os.listdir(folder)\n",
        "print(\"Files found:\", files)\n",
        "\n",
        "if 'default.csv' in files:\n",
        "    os.remove(os.path.join(folder, 'default.csv'))\n",
        "    print(\"Removed default.csv\")\n",
        "if 'add_a_comment.csv' in files:\n",
        "    os.remove(os.path.join(folder, 'add_a_comment.csv'))\n",
        "    print(\"Removed add_a_comment.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyzLhhAdIiLx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dfs = {} # all the dataframes\n",
        "for file_name in files:\n",
        "  if file_name.endswith('.csv'):\n",
        "    df_name = file_name.replace('.csv', '')\n",
        "    try:\n",
        "      dfs[df_name] = pd.read_csv(os.path.join(folder, file_name))\n",
        "      # print(f\"Successfully created DataFrame for {file_name}\")\n",
        "    except Exception as e:\n",
        "      print(f\"[ERROR] Failed to create DataFrame for {file_name} - {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdaP2jHXAwjN"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tizt1w9PYUkg"
      },
      "outputs": [],
      "source": [
        "dfs = {} # all the dataframes\n",
        "for file_name in files:\n",
        "  if file_name.endswith('.csv'):\n",
        "    df_name = file_name.replace('.csv', '')\n",
        "    try:\n",
        "      dfs[df_name] = pd.read_csv(os.path.join(folder, file_name))\n",
        "      # print(f\"Successfully created DataFrame for {file_name}\")\n",
        "    except Exception as e:\n",
        "      print(f\"[ERROR] Failed to create DataFrame for {file_name} - {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GO_xMlcJAAh"
      },
      "outputs": [],
      "source": [
        "dataframes = dfs.values()\n",
        "\n",
        "for df in dataframes:\n",
        "    if 'Title' in df.columns:\n",
        "        df.drop('Title', axis=1, inplace=True)\n",
        "    if 'URL' in df.columns:\n",
        "        df.drop('URL', axis=1, inplace=True)\n",
        "    if 'Availability' in df.columns:\n",
        "        df.drop('Availability', axis=1, inplace=True)\n",
        "    if 'Price' in df.columns:\n",
        "        df['Price'] = df['Price'].astype(str).str.replace('Â', '', regex=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn-P_wfzJbsU"
      },
      "outputs": [],
      "source": [
        "# print(list(dfs.values())[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NAAC_AzKV3F",
        "outputId": "10f705a3-2e0b-4577-bc46-437c1abafca5"
      },
      "outputs": [],
      "source": [
        "category_names = [name.replace('_', ' ').title() for name in dfs.keys()]\n",
        "# category_names.remove('Default')\n",
        "print(category_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9RdYFs2TE4h"
      },
      "source": [
        "## Statistical Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAMDsF-2TGtm"
      },
      "source": [
        "Before plotting, this section computes and displays key statistics from the scraped data. It calculates the total number of books, average price, and average rating for each category as well as the overall totals. The results are printed in a formatted summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IfP-YOG3zxw",
        "outputId": "00c20f32-b63b-4bec-d829-097229035b3d"
      },
      "outputs": [],
      "source": [
        "total_books_overall = 0\n",
        "total_price_overall = 0.0\n",
        "total_rating_overall = 0.0\n",
        "total_books_count = 0\n",
        "\n",
        "print(\"--- Basic Statistics per Dataframe ---\")\n",
        "for i, df in enumerate(dataframes):\n",
        "    category_name = category_names[i]\n",
        "    total_books_df = len(df)\n",
        "    avg_price_df = df['Price'].astype(float).mean() if total_books_df > 0 else 0\n",
        "    avg_rating_df = df['Star Rating'].mean() if total_books_df > 0 else 0\n",
        "\n",
        "    print(f\"\\nCategory: {category_name}\")\n",
        "    print(f\"Total books: {total_books_df}\")\n",
        "    print(f\"Average book price: £{avg_price_df:.2f}\")\n",
        "    print(f\"Average rating: {avg_rating_df:.2f}\")\n",
        "\n",
        "    total_books_overall += total_books_df\n",
        "    total_price_overall += df['Price'].astype(float).sum()\n",
        "    total_rating_overall += df['Star Rating'].sum()\n",
        "    total_books_count += total_books_df\n",
        "\n",
        "print(\"\\n--- Overall Basic Statistics ---\")\n",
        "avg_price_overall = total_price_overall / total_books_count if total_books_count > 0 else 0\n",
        "avg_rating_overall = total_rating_overall / total_books_count if total_books_count > 0 else 0\n",
        "\n",
        "print(f\"Total books overall: {total_books_overall}\")\n",
        "print(f\"Average price overall: £{avg_price_overall:.2f}\")\n",
        "print(f\"Average rating overall: {avg_rating_overall:.2f}\")\n",
        "\n",
        "print(\"\\n--- Average Rating per Category ---\")\n",
        "for i, df in enumerate(dataframes):\n",
        "    category_name = category_names[i]\n",
        "    avg_rating_df = df['Star Rating'].mean() if len(df) > 0 else 0\n",
        "    print(f\"{category_name}: {avg_rating_df:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh2JgTqZCapk"
      },
      "outputs": [],
      "source": [
        "# Compute statistics\n",
        "category_book_counts = {name: len(df) for name, df in zip(category_names, dataframes)}\n",
        "category_avg_prices = {name: df['Price'].astype(float).mean() if len(df) > 0 else 0 for name, df in zip(category_names, dataframes)}\n",
        "category_ratings = {name: df['Star Rating'].mean() if len(df) > 0 else 0 for name, df in zip(category_names, dataframes)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8mbgK5BTNNt"
      },
      "source": [
        "## Data Visualisations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-W7RnSYTQLE"
      },
      "source": [
        "The final section is dedicated to creating a variety of plots to visualize the data insights.\n",
        "\n",
        "**Bar Graphs**: Three separate bar charts are created to show: Total books per category, Average price per category, Average star rating per category.\n",
        "\n",
        "**Box Plots**: Two box plots are generated to show the distribution of: Prices within each category, Star ratings within each category,\n",
        "\n",
        "**Heatmap**: A heatmap is created to visualize the distribution of star ratings (1 through 5) across all scraped categories.\n",
        "\n",
        "**Histograms**: Two histograms are generated to show the overall distribution of prices and star ratings across all books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caDIn8jdDtlJ"
      },
      "outputs": [],
      "source": [
        "# Combine for distribution plots\n",
        "combined_df = pd.concat([df.assign(Category=cat) for df, cat in zip(dataframes, category_names)], ignore_index=True)\n",
        "combined_df['Price'] = combined_df['Price'].astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q519TmyHTxBP"
      },
      "source": [
        "### Bar Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "0rmngfVbDypn",
        "outputId": "f1e52959-243f-4eea-9737-b630d4b00b2f"
      },
      "outputs": [],
      "source": [
        "# Bar Graph - Total Books per Category\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=list(category_book_counts.keys()), y=list(category_book_counts.values()))\n",
        "plt.title('Total Books per Category')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Total Books')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "iSFHwYI3D1NA",
        "outputId": "eeb5bed1-0bea-46c4-c334-57e878d4c273"
      },
      "outputs": [],
      "source": [
        "# Bar Graph - Average Price per Category\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=list(category_avg_prices.keys()), y=list(category_avg_prices.values()))\n",
        "plt.title('Average Price per Category')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Average Price (£)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "Hv-wZtyRECC9",
        "outputId": "d78e76ec-6059-4ce8-b4a2-5464a8604ed6"
      },
      "outputs": [],
      "source": [
        "# Bar Graph - Average Rating per Category\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=list(category_ratings.keys()), y=list(category_ratings.values()))\n",
        "plt.title('Average Rating per Category')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Average Star Rating')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC6EbCmYT2om"
      },
      "source": [
        "### Box plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "BuWRtreKLE5x",
        "outputId": "050bec7a-28e1-4790-b092-e308f9b59fcd"
      },
      "outputs": [],
      "source": [
        "# Box Plots for Price Distributions\n",
        "plt.figure(figsize=(14, 6))\n",
        "# plt.subplot(1, 2, 1)\n",
        "sns.boxplot(x='Category', y='Price', data=combined_df)\n",
        "plt.title('Price Distribution per Category')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Price (£)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "fmAQCm4YEEJ5",
        "outputId": "3232ddf0-b089-4eb5-ac4d-c3d98a09b0c2"
      },
      "outputs": [],
      "source": [
        "# Box Plots for Rating Distributions\n",
        "plt.figure(figsize=(14, 6))\n",
        "# plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x='Category', y='Star Rating', data=combined_df)\n",
        "plt.title('Star Rating Distribution per Category')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Star Rating')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt7RWxGUUCmE"
      },
      "source": [
        "## Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "1shskr0JEHMX",
        "outputId": "2f805081-7e12-4629-9d1b-029197633f86"
      },
      "outputs": [],
      "source": [
        "# Histogram - Overall Price Distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(combined_df['Price'], bins=20, kde=True)\n",
        "plt.title('Overall Price Distribution')\n",
        "plt.xlabel('Price (£)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "l_6MtPN2EKQc",
        "outputId": "9d1d4082-fc91-4a71-c228-51689c105546"
      },
      "outputs": [],
      "source": [
        "# Histogram - Overall Star Rating Distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(combined_df['Star Rating'], bins=5, kde=False)\n",
        "plt.title('Overall Star Rating Distribution')\n",
        "plt.xlabel('Star Rating')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(range(6))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9KeliXLUI4e"
      },
      "source": [
        "## Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "d62DRNpLEM46",
        "outputId": "ab7d47e6-cde0-44d5-be14-d0d7cbc2629a"
      },
      "outputs": [],
      "source": [
        "# Heatmap - Distribution of Star Ratings Across Categories\n",
        "rating_category_counts = combined_df.groupby(['Category', 'Star Rating']).size().unstack(fill_value=0)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.heatmap(rating_category_counts, annot=True, fmt='d', cmap='YlGnBu')\n",
        "plt.title('Distribution of Star Ratings Across Categories')\n",
        "plt.xlabel('Star Rating')\n",
        "plt.ylabel('Category')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
